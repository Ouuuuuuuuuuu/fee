import streamlit as st
import pandas as pd
import datetime
from datetime import date
import requests
import json
import base64
from io import StringIO, BytesIO
import os
import fitz  # PyMuPDF
import re
from openai import OpenAI
import concurrent.futures
import time
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image  # æ–°å¢ï¼šç”¨äºæé€Ÿå›¾ç‰‡å‹ç¼©

# ==================== é¡µé¢é…ç½®ä¸æ ·å¼ ====================
st.set_page_config(page_title="AI è´¦æœ¬ Pro (GitHubç‰ˆ)", page_icon="ğŸš€", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #ffffff; }
    div[data-testid="stMetricValue"] { font-size: 2rem; font-weight: 800; color: #2563eb; }
    .stAlert { border: 1px solid #e5e7eb; border-radius: 0.5rem; padding: 1rem; }
    .stTabs [data-baseweb="tab-list"] { gap: 2px; }
    .stTabs [data-baseweb="tab"] { border-radius: 0.25rem; }
</style>
""", unsafe_allow_html=True)

# ==================== å¸¸é‡é…ç½® ====================
# --- æ¨¡å‹è®¾ç½® (å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šæ¨¡å‹) ---
VISION_MODEL_NAME = "Qwen/Qwen3-VL-8B-Instruct"
TEXT_MODEL_NAME = "deepseek-ai/DeepSeek-V3.2"

GITHUB_API_URL = "https://api.github.com"
CHUNK_SIZE = 12000
BILL_CYCLE_DAY = 10

ALLOWED_CATEGORIES = [
    "é¤é¥®ç¾é£Ÿ", "äº¤é€šå‡ºè¡Œ", "è´­ç‰©æ¶ˆè´¹", "ç”Ÿæ´»æœåŠ¡", "åŒ»ç–—å¥åº·", 
    "å·¥èµ„æ”¶å…¥", "ç†è´¢æŠ•èµ„", "è½¬è´¦çº¢åŒ…", "å…¶ä»–"
]

# ==================== æ ¸å¿ƒå·¥å…·ä¸é€»è¾‘ ====================

def get_llm_client(api_key):
    return OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")

def get_fiscal_range(current_date, cycle_day=BILL_CYCLE_DAY):
    if isinstance(current_date, str):
        current_date = datetime.datetime.strptime(current_date, "%Y-%m-%d").date()
    elif isinstance(current_date, datetime.datetime):
        current_date = current_date.date()

    if current_date.day >= cycle_day:
        start_date = date(current_date.year, current_date.month, cycle_day)
        if current_date.month == 12:
            end_date = date(current_date.year + 1, 1, cycle_day) - datetime.timedelta(days=1)
        else:
            end_date = date(current_date.year, current_date.month + 1, cycle_day) - datetime.timedelta(days=1)
    else:
        if current_date.month == 1:
            start_date = date(current_date.year - 1, 12, cycle_day)
        else:
            start_date = date(current_date.year, current_date.month - 1, cycle_day)
        end_date = date(current_date.year, current_date.month, cycle_day) - datetime.timedelta(days=1)
    return start_date, end_date

# --- æ ¸å¿ƒæé€Ÿï¼šæé€Ÿå›¾ç‰‡å‹ç¼© (ä¿®å¤é€Ÿåº¦é—®é¢˜çš„å…³é”®) ---
def optimize_image(img_bytes, max_dim=1280, quality=85):
    """å°†å›¾ç‰‡å‹ç¼©è‡³ 1280px å®½ä»¥å†…ï¼Œå¤§å¹…å‡å°‘ Token æ¶ˆè€—ï¼Œæå‡ API é€Ÿåº¦"""
    try:
        img = Image.open(BytesIO(img_bytes))
        if img.mode in ("RGBA", "P"): img = img.convert("RGB")
        
        if img.width > max_dim or img.height > max_dim:
            ratio = min(max_dim / img.width, max_dim / img.height)
            new_size = (int(img.width * ratio), int(img.height * ratio))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
            
        buffer = BytesIO()
        img.save(buffer, format="JPEG", quality=quality, optimize=True)
        return buffer.getvalue()
    except Exception as e:
        return img_bytes

def get_fund_realtime_valuation(fund_code):
    url = f"http://fundgz.1234567.com.cn/js/{fund_code}.js?rt={int(time.time()*1000)}"
    try:
        resp = requests.get(url, timeout=3)
        if resp.status_code == 200:
            content = resp.text
            match = re.search(r'jsonpgz\((.*?)\);', content)
            if match:
                data = json.loads(match.group(1))
                price = data.get('gsz') or data.get('dwjz')
                name = data.get('name')
                if price: return float(price), name
    except Exception:
        pass
    return 0.0, None

# ==================== æ•°æ®ç®¡ç†ç±» (GitHub åŸç”Ÿé€»è¾‘) ====================

class DataManager:
    def __init__(self, github_token=None, repo=None, filename="ledger.csv"):
        self.github_token = github_token
        if repo and repo.startswith("http"):
            self.repo = repo.rstrip("/").split("github.com/")[-1]
        else:
            self.repo = repo
        self.filename = filename
        self.use_github = bool(github_token and self.repo)

    def load_data(self, force_refresh=False):
        if self.use_github:
            if force_refresh: self._fetch_github_content.clear()
            df, sha = self._load_from_github()
        else:
            df, sha = self._load_from_local()

        if "ledger" in self.filename:
            df = self._clean_ledger_types(df)
        elif "funds" in self.filename:
            df = self._clean_fund_types(df)
        return df, sha

    def save_data(self, df, sha=None):
        save_df = df.copy()
        if "ledger" in self.filename and 'æ—¥æœŸ' in save_df.columns:
            # ä¿å­˜è½¬ä¸ºå­—ç¬¦ä¸²
            save_df['æ—¥æœŸ'] = save_df['æ—¥æœŸ'].astype(str)
        if "funds" in self.filename and 'åŸºé‡‘ä»£ç ' in save_df.columns:
            save_df['åŸºé‡‘ä»£ç '] = save_df['åŸºé‡‘ä»£ç '].astype(str)

        if self.use_github:
            success, new_sha = self._save_to_github(save_df, sha)
            return success, new_sha
        else:
            return self._save_to_local(save_df), None

    @staticmethod
    def _clean_ledger_types(df):
        expected_cols = ["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]
        for col in expected_cols:
            if col not in df.columns: df[col] = ""
        df['é‡‘é¢'] = pd.to_numeric(df['é‡‘é¢'], errors='coerce').fillna(0.0)
        # ä¿®å¤ï¼šå¼ºåˆ¶è½¬ä¸ºdateå¯¹è±¡ï¼Œæ–¹ä¾¿åç»­è®¡ç®—
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce').dt.date
        df['æ—¥æœŸ'] = df['æ—¥æœŸ'].fillna(date.today())
        df['ç±»å‹'] = df['ç±»å‹'].astype(str).replace('nan', 'æ”¯å‡º')
        df['åˆ†ç±»'] = df['åˆ†ç±»'].astype(str).replace('nan', 'å…¶ä»–')
        df['å¤‡æ³¨'] = df['å¤‡æ³¨'].astype(str).replace('nan', '')
        return df.sort_values('æ—¥æœŸ', ascending=False).reset_index(drop=True)

    @staticmethod
    def _clean_fund_types(df):
        expected_cols = ["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"]
        for col in expected_cols:
            if col not in df.columns: df[col] = ""
        df['åŸºé‡‘ä»£ç '] = df['åŸºé‡‘ä»£ç '].astype(str).str.replace(r'\.0$', '', regex=True).str.zfill(6)
        df['æŒæœ‰ä»½é¢'] = pd.to_numeric(df['æŒæœ‰ä»½é¢'], errors='coerce').fillna(0.0)
        df['æˆæœ¬é‡‘é¢'] = pd.to_numeric(df['æˆæœ¬é‡‘é¢'], errors='coerce').fillna(0.0)
        df['åŸºé‡‘åç§°'] = df['åŸºé‡‘åç§°'].astype(str)
        return df

    def _load_from_local(self):
        if os.path.exists(self.filename):
            try: return pd.read_csv(self.filename, dtype=str), None
            except: pass
        if "ledger" in self.filename:
            return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None
        else:
            return pd.DataFrame(columns=["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"]), None

    def _save_to_local(self, df):
        df.to_csv(self.filename, index=False)
        return True

    @st.cache_data(ttl=300, show_spinner=False)
    def _fetch_github_content(_self):
        headers = {"Authorization": f"token {_self.github_token}", "Accept": "application/vnd.github.v3+json"}
        url = f"{GITHUB_API_URL}/repos/{_self.repo}/contents/{_self.filename}"
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200: return response.json(), None
            elif response.status_code == 404: return None, 404
            else: return None, response.status_code
        except Exception as e: return None, str(e)

    def _load_from_github(self):
        content, error = self._fetch_github_content()
        if content:
            try:
                csv_str = base64.b64decode(content['content']).decode('utf-8')
                df = pd.read_csv(StringIO(csv_str), dtype=str)
                return df, content['sha']
            except: 
                if "ledger" in self.filename:
                    return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None
                else:
                    return pd.DataFrame(columns=["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"]), None
        if "ledger" in self.filename:
            return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None
        else:
            return pd.DataFrame(columns=["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"]), None

    def _save_to_github(self, df, sha):
        headers = {"Authorization": f"token {self.github_token}", "Accept": "application/vnd.github.v3+json"}
        url = f"{GITHUB_API_URL}/repos/{self.repo}/contents/{self.filename}"
        csv_str = df.to_csv(index=False)
        content_bytes = base64.b64encode(csv_str.encode('utf-8')).decode('utf-8')
        data = {"message": f"Update {self.filename}", "content": content_bytes}
        if sha: data["sha"] = sha
        try:
            resp = requests.put(url, headers=headers, data=json.dumps(data), timeout=30)
            if resp.status_code in [200, 201]:
                self._fetch_github_content.clear()
                return True, resp.json()['content']['sha']
            elif resp.status_code in [409, 422]:
                self._fetch_github_content.clear()
                latest_content, _ = self._fetch_github_content()
                if latest_content:
                    data["sha"] = latest_content['sha']
                    retry = requests.put(url, headers=headers, data=json.dumps(data), timeout=30)
                    if retry.status_code in [200, 201]:
                        self._fetch_github_content.clear()
                        return True, retry.json()['content']['sha']
                return False, None
        except: return False, None

# ==================== AI è§£æå™¨ (æ•´åˆæé€Ÿé€»è¾‘) ====================

class TurboParser:
    @staticmethod
    def _pdf_to_images(file_bytes):
        images = []
        try:
            with fitz.open(stream=file_bytes, filetype="pdf") as doc:
                for page in doc:
                    # æ”¾å¤§ä¸€å€ä¿è¯æ¸…æ™°åº¦
                    pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
                    images.append(pix.tobytes("png"))
        except Exception as e:
            st.error(f"PDFè½¬å›¾ç‰‡é”™è¯¯: {e}")
        return images

    @staticmethod
    def process_image(filename, raw_file_bytes, api_key):
        try:
            # 1. æé€Ÿå‹ç¼©
            optimized_bytes = optimize_image(raw_file_bytes)
            b64_img = base64.b64encode(optimized_bytes).decode('utf-8')
            
            client = get_llm_client(api_key)
            
            prompt_text = f"""
            åˆ†æè¿™å¼ è´¦å•/æµæ°´ã€‚
            ä»»åŠ¡ï¼šæå–äº¤æ˜“æ˜ç»†ã€‚
            
            **è§„åˆ™**ï¼š
            1. æ—¥æœŸæ ¼å¼è½¬æ¢ä¸º YYYY-MM-DD (å…¼å®¹ 2025/12/30)ã€‚
            2. æ”¯å‡ºè®°ä¸º "æ”¯å‡º"ï¼Œæ”¶å…¥è®°ä¸º "æ”¶å…¥"ã€‚
            3. è‡ªåŠ¨å½’å…¥åˆ†ç±»ï¼Œä»…ä» {ALLOWED_CATEGORIES} ä¸­é€‰ã€‚
            4. **å»é‡æ•æ„Ÿ**ï¼šå¦‚æœåŒä¸€æ—¥æœ‰ç›¸åŒé‡‘é¢ï¼Œè¯·åŠ¡å¿…é€šè¿‡å•†æˆ·ååŒºåˆ† (å¦‚ "æ˜Ÿå·´å…‹Aåº—", "æ˜Ÿå·´å…‹Båº—")ã€‚

            **Strict Output JSON**:
            {{"records": [{{"date":"YYYY-MM-DD","type":"æ”¯å‡º","amount":10.5,"merchant":"å•†æˆ·","category":"åˆ†ç±»"}}]}}
            """

            resp = client.chat.completions.create(
                model=VISION_MODEL_NAME, # Qwen3-VL
                messages=[{
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}}
                    ]
                }],
                response_format={"type": "json_object"},
                max_tokens=2048
            )
            
            parsed = json.loads(resp.choices[0].message.content)
            data = parsed.get("records", [])
            
            if not data: return None
            df = pd.DataFrame(data)
            cols_map = {"date": "æ—¥æœŸ", "type": "ç±»å‹", "amount": "é‡‘é¢", "merchant": "å¤‡æ³¨", "category": "åˆ†ç±»"}
            return df.rename(columns=cols_map)

        except Exception as e: 
            return None

    @staticmethod
    def identify_and_parse(filename, file_bytes, api_key):
        filename_lower = filename.lower()
        
        if filename_lower.endswith('.pdf'):
            images = TurboParser._pdf_to_images(file_bytes)
            if not images: return None
            
            # å¹¶å‘å¤„ç†PDFæ¯ä¸€é¡µ
            final_df = pd.DataFrame()
            with st.status(f"æ­£åœ¨å¤„ç† PDF (å…± {len(images)} é¡µ)..."):
                with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                    futures = [executor.submit(TurboParser.process_image, f"p{i}", img, api_key) for i, img in enumerate(images)]
                    for future in concurrent.futures.as_completed(futures):
                        res = future.result()
                        if res is not None:
                            final_df = pd.concat([final_df, res], ignore_index=True)
            return final_df
        
        elif filename_lower.endswith(('.png', '.jpg', 'jpeg')):
            return TurboParser.process_image(filename, file_bytes, api_key)
        
        return None

# ==================== ä¸»ç¨‹åºé€»è¾‘ ====================

def main():
    # åˆå§‹åŒ– Session State
    if 'ledger_data' not in st.session_state: st.session_state.ledger_data = pd.DataFrame()
    if 'fund_data' not in st.session_state: st.session_state.fund_data = pd.DataFrame()
    if 'fund_prices' not in st.session_state: st.session_state.fund_prices = {}
    if 'api_key' not in st.session_state: st.session_state.api_key = st.secrets.get("SILICONFLOW_API_KEY")

    # é…ç½®
    gh_token = st.secrets.get("GITHUB_TOKEN")
    gh_repo = st.secrets.get("GITHUB_REPO")

    # --- æ•°æ®åŠ è½½ ---
    dm_ledger = DataManager(gh_token, gh_repo, "ledger.csv")
    dm_funds = DataManager(gh_token, gh_repo, "funds.csv")
    
    # å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œä»äº‘ç«¯åŠ è½½
    if st.session_state.ledger_data.empty and gh_token:
        df, sha = dm_ledger.load_data()
        st.session_state.ledger_data = df
        st.session_state.ledger_sha = sha
    
    if st.session_state.fund_data.empty and gh_token:
        df, sha = dm_funds.load_data()
        st.session_state.fund_data = df
        st.session_state.fund_sha = sha

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.title("âš™ï¸ è®¾ç½®")
        st.session_state.api_key = st.text_input("API Key", value=st.session_state.api_key or "", type="password", label_visibility="collapsed", placeholder="Enter SiliconFlow Key")
        
        if gh_token and gh_repo:
            st.success("â˜ï¸ GitHub å·²è¿æ¥")
            if st.button("ğŸ”„ å¼ºåˆ¶åˆ·æ–°äº‘ç«¯", use_container_width=True):
                with st.spinner("åŒæ­¥ä¸­..."):
                    df, sha = dm_ledger.load_data(force_refresh=True)
                    st.session_state.ledger_data = df; st.session_state.ledger_sha = sha
                    df, sha = dm_funds.load_data(force_refresh=True)
                    st.session_state.fund_data = df; st.session_state.fund_sha = sha
                    st.rerun()

    # è´¢åŠ¡æ¦‚è§ˆ
    default_start, default_end = get_fiscal_range(date.today())
    df_ledger = st.session_state.ledger_data
    if not df_ledger.empty:
        cash_net = df_ledger[df_ledger['ç±»å‹']=='æ”¶å…¥']['é‡‘é¢'].sum() - df_ledger[df_ledger['ç±»å‹']=='æ”¯å‡º']['é‡‘é¢'].sum()
        
        df_ledger['dt'] = pd.to_datetime(df_ledger['æ—¥æœŸ'], errors='coerce').dt.date
        mask_period = (df_ledger['dt'] >= default_start) & (df_ledger['dt'] <= default_end)
        df_period = df_ledger[mask_period]
        current_income = df_period[df_period['ç±»å‹']=='æ”¶å…¥']['é‡‘é¢'].sum()
        current_expense = df_period[df_period['ç±»å‹']=='æ”¯å‡º']['é‡‘é¢'].sum()
    else:
        cash_net = current_income = current_expense = 0.0

    # è´¦é¢èµ„äº§è®¡ç®—
    fund_val = 0.0
    if not st.session_state.fund_data.empty:
        df_funds = st.session_state.fund_data
        df_funds['æŒæœ‰ä»½é¢'] = pd.to_numeric(df_funds['æŒæœ‰ä»½é¢'], errors='coerce').fillna(0)
        # å¦‚æœæœ‰ç¼“å­˜ä»·æ ¼ï¼Œè®¡ç®—å¸‚å€¼
        for code in df_funds['åŸºé‡‘ä»£ç '].unique():
            if code in st.session_state.fund_prices:
                price = st.session_state.fund_prices[code]
                shares = df_funds[df_funds['åŸºé‡‘ä»£ç ']==code]['æŒæœ‰ä»½é¢'].sum()
                fund_val += shares * price

    st.divider()
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ğŸ’° æ€»å‡€èµ„äº§", f"Â¥{cash_net + fund_val:,.2f}")
    c2.metric("ğŸ“… æœ¬æœŸæ”¯å‡º", f"Â¥{current_expense:,.2f}", delta_color="inverse")
    c3.metric("ğŸ“… æœ¬æœŸæ”¶å…¥", f"Â¥{current_income:,.2f}")
    c4.metric("ğŸ“ˆ åŸºé‡‘å¸‚å€¼", f"Â¥{fund_val:,.2f}")

    # Tabs
    t_import, t_add, t_history, t_funds, t_stats, t_copilot = st.tabs(["ğŸ“¥ å¯¼å…¥", "âœï¸ è®°è´¦", "ğŸ“‹ æ˜ç»†", "ğŸ“ˆ åŸºé‡‘", "ğŸ“Š æŠ¥è¡¨", "ğŸ§  AI Copilot"])

    # --- å¯¼å…¥ ---
    with t_import:
        files = st.file_uploader("ä¸Šä¼ è´¦å• (PDF/å›¾ç‰‡)", accept_multiple_files=True, type=['csv', 'png', 'jpg', 'jpeg', 'pdf'])
        if files and st.button("ğŸš€ æé€Ÿè§£æ", type="primary"):
            if not st.session_state.api_key: st.error("è¯·å…ˆè¾“å…¥ API Key"); st.stop()
            
            status = st.status("AI Agent æ­£åœ¨å¤„ç†...", expanded=True)
            all_new = pd.DataFrame()
            
            start_time = time.time()
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                futures = {executor.submit(TurboParser.identify_and_parse, f.name, f.read(), st.session_state.api_key): f.name for f in files}
                for future in concurrent.futures.as_completed(futures):
                    fname = futures[future]
                    try:
                        res = future.result()
                        if res is not None and not res.empty:
                            all_new = pd.concat([all_new, res], ignore_index=True)
                            status.write(f"âœ… âœ¨ {fname} å®Œæˆ ({len(res)} æ¡)")
                        else:
                            status.write(f"âš ï¸ {fname} æœªè¯†åˆ«åˆ°æ•°æ®")
                    except Exception as e:
                        status.write(f"âŒ {fname} é”™è¯¯")
            
            status.update(label=f"å®Œæˆ! è€—æ—¶ {time.time()-start_time:.2f}s", state="complete", expanded=False)
            
            if not all_new.empty:
                # åˆå¹¶ä¸æ¸…æ´—
                old_df = st.session_state.ledger_data
                # æ ‡å‡†åŒ–æ—¥æœŸä»¥ä¾¿åˆå¹¶
                all_new['æ—¥æœŸ'] = pd.to_datetime(all_new['æ—¥æœŸ'], errors='coerce').dt.date
                merged_df, cnt = merge_data_with_overwrite(old_df, all_new)
                
                # ä¿å­˜
                ok, sha = dm_ledger.save_data(merged_df, st.session_state.get('ledger_sha'))
                if ok:
                    st.session_state.ledger_data = merged_df
                    st.session_state.ledger_sha = sha
                    st.success(f"æˆåŠŸåˆå¹¶ {cnt} æ¡æ•°æ®ï¼")
                    st.rerun()

    # --- æ‰‹åŠ¨è®°è´¦ ---
    with t_add:
        with st.form("manual", clear_on_submit=True):
            c1, c2, c3 = st.columns(3)
            d = c1.date_input("æ—¥æœŸ", value=date.today(), label_visibility="collapsed")
            t = c2.selectbox("ç±»å‹", ["æ”¯å‡º", "æ”¶å…¥"], label_visibility="collapsed")
            a = c3.number_input("é‡‘é¢", min_value=0.01, step=0.01, label_visibility="collapsed")
            c4, c5 = st.columns([1, 2])
            cat = c4.selectbox("åˆ†ç±»", ALLOWED_CATEGORIES, label_visibility="collapsed")
            rem = c5.text_input("å¤‡æ³¨", placeholder="æ¶ˆè´¹å†…å®¹...", label_visibility="collapsed")
            
            submitted = st.form_submit_button("ä¿å­˜è®°å½•", use_container_width=True)
            if submitted:
                row = pd.DataFrame([{"æ—¥æœŸ":d,"ç±»å‹":t,"é‡‘é¢":float(a),"åˆ†ç±»":cat,"å¤‡æ³¨":rem}])
                # ç¡®ä¿ row æ—¥æœŸæ˜¯ date å¯¹è±¡
                row['æ—¥æœŸ'] = pd.to_datetime(row['æ—¥æœŸ']).dt.date
                merged, _ = merge_data_with_overwrite(st.session_state.ledger_data, row)
                ok, sha = dm_ledger.save_data(merged, st.session_state.get('ledger_sha'))
                if ok: 
                    st.session_state.ledger_data = merged
                    st.session_state.ledger_sha = sha
                    st.success("ä¿å­˜æˆåŠŸ")
                    st.rerun()

    # --- å†å²æ˜ç»† (Bug ä¿®å¤ä½ç½®) ---
    with t_history:
        if st.session_state.ledger_data.empty: st.info("æš‚æ— æ•°æ®")
        else:
            df_temp = st.session_state.ledger_data.copy()
            # *** ä¿®å¤å…³é”®æ­¥éª¤ ***
            # å‡†å¤‡ç»™ st.data_editor çš„æ•°æ®ï¼š
            # 1. ç¡®ä¿æ—¥æœŸåˆ—æ˜¯ datetime.date å¯¹è±¡ï¼Œä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå¦åˆ™ column_config.DateColumn ä¼šæŠ¥é”™
            # 2. ç¡®ä¿å…¶ä»–ç±»å‹æ­£ç¡®
            df_temp['æ—¥æœŸ'] = pd.to_datetime(df_temp['æ—¥æœŸ'], errors='coerce').dt.date
            df_temp = df_temp.sort_values("æ—¥æœŸ", ascending=False)
            
            # å¡«å……å¯èƒ½å­˜åœ¨çš„ NaN é¿å…ç±»å‹æ­§ä¹‰
            for col in df_temp.columns:
                if df_temp[col].dtype == 'object': df_temp[col] = df_temp[col].fillna("")

            edited_df = st.data_editor(
                df_temp,
                use_container_width=True,
                num_rows="dynamic",
                column_order=["æ—¥æœŸ", "ç±»å‹", "åˆ†ç±»", "é‡‘é¢", "å¤‡æ³¨"],
                key="editor_history",
                column_config={
                    # æ˜ç¡®è¯´æ˜æ—¥æœŸæ ¼å¼ï¼Œå› ä¸ºç¼–è¾‘å™¨å†…éƒ¨æ ¼å¼å¾ˆå¥½
                    "æ—¥æœŸ": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD", step=1),
                    "åˆ†ç±»": st.column_config.SelectboxColumn(options=ALLOWED_CATEGORIES),
                    "é‡‘é¢": st.column_config.NumberColumn(format="%.2f"),
                    "ç±»å‹": st.column_config.SelectboxColumn(options=["æ”¯å‡º", "æ”¶å…¥"])
                }
            )
            if st.button("ğŸ’¾ ä¿å­˜è¡¨æ ¼ä¿®æ”¹", use_container_width=True):
                # ç¼–è¾‘åçš„æ•°æ®å·²ç»æ˜¯ date å¯¹è±¡äº†ï¼Œç›´æ¥ä¿å­˜
                ok, sha = dm_ledger.save_data(edited_df, st.session_state.get('ledger_sha'))
                if ok:
                    st.session_state.ledger_data = edited_df
                    st.session_state.ledger_sha = sha
                    st.success("ä¿®æ”¹å·²ä¿å­˜")
                    time.sleep(0.5); st.rerun()

    # --- åŸºé‡‘ ---
    with t_funds:
        c_f1, c_f2 = st.columns([1, 3])
        with c_f1:
            st.subheader("ğŸ“¸ å¯¼å…¥æŒä»“")
            fund_files = st.file_uploader("ä¸Šä¼ æˆªå›¾", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
            if fund_files and st.button("è¯†åˆ«æŒä»“", use_container_width=True):
                if not st.session_state.api_key: st.error("è¯·é…ç½® API Key"); st.stop()
                new_funds = pd.DataFrame()
                with st.status("æ­£åœ¨è¯†åˆ«..."):
                    for f in fund_files:
                        f.seek(0)
                        # å¤ç”¨ process_image é€»è¾‘ (ç•¥ä½œä¿®æ”¹ä»¥é€‚é…åŸºé‡‘)
                        # è¿™é‡Œç®€åŒ–ï¼šç›´æ¥æŒ‰åŸºé‡‘ Prompt å¤„ç†
                        try:
                            optimized = optimize_image(f.read())
                            b64 = base64.b64encode(optimized).decode()
                            client = get_llm_client(st.session_state.api_key)
                            prompt = """
                            æå–åŸºé‡‘æŒä»“ã€‚å­—æ®µ: code(ä»£ç ), name(åç§°), share(ä»½é¢), cost(æˆæœ¬)ã€‚
                            å¿½ç•¥å¸‚å€¼ã€‚
                            JSON: {{"records": [{{"code":"000001","name":"åå¤","share":1000,"cost":1000}}]}}
                            """
                            resp = client.chat.completions.create(
                                model=VISION_MODEL_NAME,
                                messages=[{"role":"user", "content": [{"type":"text", "text":prompt}, {"type":"image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}]}],
                                response_format={"type": "json_object"}
                            )
                            data = json.loads(resp.choices[0].message.content).get("records", [])
                            if data:
                                temp_df = pd.DataFrame(data)
                                temp_df = temp_df.rename(columns={"code":"åŸºé‡‘ä»£ç ", "name":"åŸºé‡‘åç§°", "share":"æŒæœ‰ä»½é¢", "cost":"æˆæœ¬é‡‘é¢"})
                                new_funds = pd.concat([new_funds, temp_df])
                        except: continue
                
                if not new_funds.empty:
                    old_funds = st.session_state.fund_data
                    combined = pd.concat([old_funds, new_funds], ignore_index=True)
                    final_funds = combined.drop_duplicates(subset=['åŸºé‡‘ä»£ç '], keep='last')
                    ok, sha = dm_funds.save_data(final_funds, st.session_state.get('fund_sha'))
                    if ok:
                        st.session_state.fund_data = final_funds
                        st.success("æŒä»“æ›´æ–°æˆåŠŸ"); st.rerun()

        with c_f2:
            if st.button("ğŸ”„ åˆ·æ–°è¡Œæƒ…", use_container_width=True):
                if st.session_state.fund_data.empty: pass
                else:
                    codes = st.session_state.fund_data['åŸºé‡‘ä»£ç '].unique()
                    progress = st.progress(0)
                    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                        future_to_code = {executor.submit(get_fund_realtime_valuation, code): code for code in codes}
                        for i, future in enumerate(concurrent.futures.as_completed(future_to_code)):
                            code, val, name = future.result()
                            if val > 0: st.session_state.fund_prices[code] = {"price": val, "name": name}
                            progress.progress((i+1)/len(codes))
                    st.rerun()
            
            if st.session_state.fund_data.empty: st.info("æš‚æ— æŒä»“")
            else:
                display_data = []
                for _, row in st.session_state.fund_data.iterrows():
                    code = str(row['åŸºé‡‘ä»£ç '])
                    price = st.session_state.fund_prices.get(code, {}).get('price', 0.0)
                    name = st.session_state.fund_prices.get(code, {}).get('name', row['åŸºé‡‘åç§°'])
                    val = float(row['æŒæœ‰ä»½é¢']) * price
                    display_data.append({
                        "åŸºé‡‘ä»£ç ": code, "åŸºé‡‘åç§°": name,
                        "æŒæœ‰ä»½é¢": row['æŒæœ‰ä»½é¢'], "æœ€æ–°å‡€å€¼": price,
                        "å½“å‰å¸‚å€¼": val
                    })
                st.data_editor(pd.DataFrame(display_data), use_container_width=True, disabled=["åŸºé‡‘åç§°", "æœ€æ–°å‡€å€¼", "å½“å‰å¸‚å€¼"])

    # --- æŠ¥è¡¨ ---
    with t_stats:
        if df_ledger.empty: st.info("æš‚æ— æ•°æ®")
        else:
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(px.pie(df_ledger[df_ledger['ç±»å‹']=='æ”¯å‡º'], values='é‡‘é¢', names='åˆ†ç±»', hole=0.4), use_container_width=True)
            with col2:
                st.plotly_chart(px.bar(df_ledger, x='æ—¥æœŸ', y='é‡‘é¢', color='ç±»å‹'), use_container_width=True)

    # --- AI Copilot (åŠŸèƒ½çªç ´) ---
    with t_copilot:
        st.markdown("### ğŸ’¬ å‘ä½ çš„è´¢åŠ¡ AI æé—®")
        st.caption("ä¾‹å¦‚ï¼šä¸Šä¸ªæœˆæˆ‘åœ¨å“ªé‡ŒèŠ±é’±æœ€å¤šï¼Ÿç»Ÿè®¡ä¸€ä¸‹æ‰€æœ‰çš„é¤é¥®æ”¯å‡ºã€‚")
        user_query = st.text_input("ä½ çš„é—®é¢˜ï¼š", key="copilot_query")
        if st.button("ğŸ§  åˆ†æ", type="secondary"):
            if not st.session_state.api_key: st.error("éœ€è¦ API Key"); st.stop()
            
            if st.session_state.ledger_data.empty:
                st.warning("æ²¡æœ‰æ•°æ®ä¾›åˆ†æ")
            else:
                with st.spinner("AI æ­£åœ¨å†™ä»£ç åˆ†æ..."):
                    # åˆ›å»ºä¸€æ®µä»£ç ç¯å¢ƒä¾› LLM æ‰§è¡Œ
                    sample = st.session_state.ledger_data.head(5).to_csv(index=False)
                    
                    prompt = f"""
                    ä½ æ˜¯ Pandas ä¸“å®¶ã€‚å˜é‡åæ˜¯ `df`ã€‚
                    åˆ—å: [{', '.join(st.session_state.ledgerger_data.columns)}].
                    æ•°æ®æ ·æœ¬:
                    {sample}
                    
                    é—®é¢˜ï¼š{user_query}
                    
                    è¯·è¾“å‡º Python ä»£ç ã€‚
                    1. ä½¿ç”¨ `st.dataframe` æˆ– `st.metric` å±•ç¤ºç»“æœã€‚
                    2. å¿½ç•¥æ— å…³è­¦å‘Šã€‚
                    3. å¤„ç†æ—¥æœŸæ—¶ï¼Œå‚è€ƒ pandas dt accessorã€‚
                    4. **ä»…è¾“å‡ºä»£ç **ã€‚
                    """
                    
                    try:
                        client = get_llm_client(st.session_state.api_key)
                        resp = client.chat.completions.create(
                            model=TEXT_MODEL_NAME,
                            messages=[{"role": "user", "content": prompt}],
                            temperature=0.1,
                            max_tokens=1024
                        )
                        
                        code_str = resp.choices[0].message.content
                        if "```python" in code_str:
                            code_str = code_str.split("```python")[1].split("```")[0].strip()
                        elif "```" in code_str:
                            code_str = code_str.split("```")[1].split("```")[0].strip()
                        
                        with st.context:
                            exec_globals = {"df": st.session_state.ledger_data, "st": st, "pd": pd}
                            exec(code_str, exec_globals)
                            
                    except Exception as e:
                        st.error(f"AI åˆ†æå‡ºé”™: {e}")

def merge_data_with_overwrite(old_df, new_df):
    if new_df is None or new_df.empty: return old_df, 0
    if old_df.empty: return new_df, len(new_df)
    
    for df in [old_df.copy(), new_df.copy()]:
        df['æ—¥æœŸ'] = df['æ—¥æœŸ'].astype(str).str.replace('/', '-')
        df['æ—¥æœŸ'] = df['æ—¥æœŸ'].str.split(' ').str[0]
        df['é‡‘é¢'] = pd.to_numeric(df['é‡‘é¢'], errors='coerce').fillna(0)
        df['å¤‡æ³¨'] = df['å¤‡æ³¨'].astype(str)
    
    merged_df = pd.concat([old_df, new_df], ignore_index=True)
    def get_fp(d): return d['æ—¥æœŸ'].astype(str) + "_" + d['é‡‘é¢'].astype(str) + "_" + d['å¤‡æ³¨'].str[:6]
    merged_df['_fp'] = get_fp(merged_df)
    final_df = merged_df.drop_duplicates(subset=['_fp'], keep='last').drop(columns=['_fp'])
    final_df['æ—¥æœŸ'] = pd.to_datetime(final_df['æ—¥æœŸ'], errors='coerce').dt.date
    return final_df.sort_values('æ—¥æœŸ', ascending=False).reset_index(drop=True), len(new_df)

if __name__ == "__main__":
    main()
