import streamlit as st
import pandas as pd
import datetime
from datetime import date
import requests
import json
import base64
from io import StringIO, BytesIO
import os
import fitz  # PyMuPDF
import re
from openai import OpenAI
import concurrent.futures
import time
import plotly.express as px

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI æ™ºèƒ½è´¦æœ¬ Pro (è§†è§‰å¢å¼ºç‰ˆ)", page_icon="ğŸ’°", layout="wide")

# --- å¸¸é‡é…ç½® ---
GITHUB_API_URL = "https://api.github.com"
# æ¨èä½¿ç”¨èƒ½åŠ›è¾ƒå¼ºçš„è§†è§‰æ¨¡å‹ï¼Œå¦‚ Qwen2.5-VL æˆ– Qwen2-VL-72B
VISION_MODEL_NAME = "Qwen/Qwen2.5-VL-72B-Instruct" 
TEXT_MODEL_NAME = "deepseek-ai/DeepSeek-V3"
CHUNK_SIZE = 12000 
BILL_CYCLE_DAY = 10  # è´¦å•æ—¥ï¼šæ¯æœˆ10å·

ALLOWED_CATEGORIES = [
    "é¤é¥®ç¾é£Ÿ", "äº¤é€šå‡ºè¡Œ", "è´­ç‰©æ¶ˆè´¹", "ç”Ÿæ´»æœåŠ¡", "åŒ»ç–—å¥åº·", "å·¥èµ„æ”¶å…¥", "ç†è´¢æŠ•èµ„", "è½¬è´¦çº¢åŒ…", "å…¶ä»–"
]

# --- æ ¸å¿ƒå·¥å…·ï¼šOpenAI Client ---
def get_llm_client(api_key):
    # è¯·ç¡®ä¿ base_url ç¬¦åˆä½ ä½¿ç”¨çš„æœåŠ¡å•† (å¦‚ SiliconFlow, DeepSeek ç­‰)
    return OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")

# --- è¾…åŠ©é€»è¾‘ ---
def get_fiscal_range(current_date, cycle_day=BILL_CYCLE_DAY):
    if isinstance(current_date, str):
        current_date = datetime.datetime.strptime(current_date, "%Y-%m-%d").date()
    elif isinstance(current_date, datetime.datetime):
        current_date = current_date.date()

    if current_date.day >= cycle_day:
        start_date = date(current_date.year, current_date.month, cycle_day)
        if current_date.month == 12:
            end_date = date(current_date.year + 1, 1, cycle_day) - datetime.timedelta(days=1)
        else:
            end_date = date(current_date.year, current_date.month + 1, cycle_day) - datetime.timedelta(days=1)
    else:
        if current_date.month == 1:
            start_date = date(current_date.year - 1, 12, cycle_day)
        else:
            start_date = date(current_date.year, current_date.month - 1, cycle_day)
        end_date = date(current_date.year, current_date.month, cycle_day) - datetime.timedelta(days=1)
    return start_date, end_date

def repair_truncated_json(json_str):
    json_str = json_str.strip()
    if json_str.endswith("]"): return json_str
    repair_attempts = ["]", "}]", "\"}]", "0}]", "null}]"]
    if json_str.endswith(","): json_str = json_str[:-1]
    for suffix in repair_attempts:
        try:
            temp_str = json_str + suffix
            json.loads(temp_str)
            return temp_str
        except: continue
    return json_str

def extract_json_from_text(text):
    if not text: return None, "ç©ºå“åº”"
    try:
        text = text.strip()
        # å°è¯•æå– Markdown ä»£ç å—
        code_block_pattern = r"``" + r"`(?:json)?(.*?)``" + r"`"
        match_code = re.search(code_block_pattern, text, re.DOTALL)
        if match_code: text = match_code.group(1).strip()
        else:
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```\s*', '', text)
            text = text.strip()
        
        text = repair_truncated_json(text)
        # æå–æ•°ç»„éƒ¨åˆ†
        match_array = re.search(r'\[.*\]', text, re.DOTALL)
        if match_array: text_to_parse = match_array.group()
        else: text_to_parse = text
            
        result = json.loads(text_to_parse)
        if isinstance(result, (list, dict)):
            return result if isinstance(result, list) else [result], None
    except: pass
    return None, "JSONæå–å¤±è´¥"

# --- åŸºé‡‘ç›¸å…³å·¥å…· ---
def get_fund_realtime_valuation(fund_code):
    """é€šè¿‡å…¬å¼€æ¥å£è·å–åŸºé‡‘ä¼°å€¼"""
    url = f"http://fundgz.1234567.com.cn/js/{fund_code}.js?rt={int(time.time()*1000)}"
    try:
        resp = requests.get(url, timeout=3)
        if resp.status_code == 200:
            content = resp.text
            match = re.search(r'jsonpgz\((.*?)\);', content)
            if match:
                data = json.loads(match.group(1))
                price = data.get('gsz') or data.get('dwjz')
                name = data.get('name')
                time_str = data.get('gztime') or data.get('jzrq')
                return float(price), name, time_str
    except Exception:
        pass
    return 0.0, None, None

# --- æ•°æ®ç®¡ç†ç±» ---
class DataManager:
    def __init__(self, github_token=None, repo=None, filename="ledger.csv"):
        self.github_token = github_token
        if repo and repo.startswith("http"):
            self.repo = repo.rstrip("/").split("github.com/")[-1]
        else:
            self.repo = repo
        self.filename = filename
        self.use_github = bool(github_token and self.repo)

    def load_data(self, force_refresh=False):
        if self.use_github:
            if force_refresh: self._fetch_github_content.clear()
            df, sha = self._load_from_github()
        else:
            df, sha = self._load_from_local()
        
        if "ledger" in self.filename:
            df = self._clean_ledger_types(df)
        elif "funds" in self.filename:
            df = self._clean_fund_types(df)
        return df, sha

    def save_data(self, df, sha=None):
        save_df = df.copy()
        if "ledger" in self.filename and 'æ—¥æœŸ' in save_df.columns:
            save_df['æ—¥æœŸ'] = save_df['æ—¥æœŸ'].astype(str)
        if "funds" in self.filename and 'åŸºé‡‘ä»£ç ' in save_df.columns:
            save_df['åŸºé‡‘ä»£ç '] = save_df['åŸºé‡‘ä»£ç '].astype(str)

        if self.use_github:
            success, new_sha = self._save_to_github(save_df, sha)
            return success, new_sha
        else:
            return self._save_to_local(save_df), None

    @staticmethod
    def merge_data(old_df, new_df):
        if new_df is None or new_df.empty: return old_df, 0
        
        def get_fp(d): return d['æ—¥æœŸ'].astype(str) + d['é‡‘é¢'].astype(str) + d['å¤‡æ³¨'].str[:5]
        if old_df.empty: return new_df, len(new_df)
        
        old_fp = set(get_fp(old_df))
        new_df['_fp'] = get_fp(new_df)
        to_add = new_df[~new_df['_fp'].isin(old_fp)].drop(columns=['_fp'])
        
        if to_add.empty: return old_df, 0
        merged = pd.concat([old_df, to_add], ignore_index=True)
        merged = DataManager._clean_ledger_types(merged)
        return merged, len(to_add)

    @staticmethod
    def _clean_ledger_types(df):
        expected_cols = ["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]
        for col in expected_cols:
            if col not in df.columns: df[col] = ""
        df['é‡‘é¢'] = pd.to_numeric(df['é‡‘é¢'], errors='coerce').fillna(0.0)
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce').dt.date
        df['æ—¥æœŸ'] = df['æ—¥æœŸ'].fillna(date.today())
        df['ç±»å‹'] = df['ç±»å‹'].astype(str).replace('nan', 'æ”¯å‡º')
        df['åˆ†ç±»'] = df['åˆ†ç±»'].astype(str).replace('nan', 'å…¶ä»–')
        df['å¤‡æ³¨'] = df['å¤‡æ³¨'].astype(str).replace('nan', '')
        df = df.sort_values('æ—¥æœŸ', ascending=False).reset_index(drop=True)
        return df

    @staticmethod
    def _clean_fund_types(df):
        expected_cols = ["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"]
        for col in expected_cols:
            if col not in df.columns: df[col] = ""
        df['åŸºé‡‘ä»£ç '] = df['åŸºé‡‘ä»£ç '].astype(str).str.replace(r'\.0$', '', regex=True).str.zfill(6)
        df['æŒæœ‰ä»½é¢'] = pd.to_numeric(df['æŒæœ‰ä»½é¢'], errors='coerce').fillna(0.0)
        df['æˆæœ¬é‡‘é¢'] = pd.to_numeric(df['æˆæœ¬é‡‘é¢'], errors='coerce').fillna(0.0)
        df['åŸºé‡‘åç§°'] = df['åŸºé‡‘åç§°'].astype(str)
        return df

    def _load_from_local(self):
        if os.path.exists(self.filename):
            try: return pd.read_csv(self.filename, dtype=str), None
            except: pass
        return self._create_empty_df(), None

    def _save_to_local(self, df):
        df.to_csv(self.filename, index=False)
        return True

    @st.cache_data(ttl=300, show_spinner=False)
    def _fetch_github_content(_self):
        headers = {"Authorization": f"token {_self.github_token}", "Accept": "application/vnd.github.v3+json"}
        url = f"{GITHUB_API_URL}/repos/{_self.repo}/contents/{_self.filename}"
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200: return response.json(), None
            elif response.status_code == 404: return None, 404
            else: return None, response.status_code
        except Exception as e: return None, str(e)

    def _load_from_github(self):
        content, error = self._fetch_github_content()
        if content:
            try:
                csv_str = base64.b64decode(content['content']).decode('utf-8')
                df = pd.read_csv(StringIO(csv_str), dtype=str)
                return df, content['sha']
            except: return self._create_empty_df(), content['sha']
        return self._create_empty_df(), None

    def _save_to_github(self, df, sha):
        headers = {"Authorization": f"token {self.github_token}", "Accept": "application/vnd.github.v3+json"}
        url = f"{GITHUB_API_URL}/repos/{self.repo}/contents/{self.filename}"
        csv_str = df.to_csv(index=False)
        content_bytes = base64.b64encode(csv_str.encode('utf-8')).decode('utf-8')
        data = {"message": f"Update {self.filename}", "content": content_bytes}
        if sha: data["sha"] = sha
        try:
            resp = requests.put(url, headers=headers, data=json.dumps(data), timeout=30)
            if resp.status_code in [200, 201]:
                self._fetch_github_content.clear()
                return True, resp.json()['content']['sha']
            elif resp.status_code in [409, 422]:
                self._fetch_github_content.clear()
                latest_content, _ = self._fetch_github_content()
                if latest_content:
                    data["sha"] = latest_content['sha']
                    retry = requests.put(url, headers=headers, data=json.dumps(data), timeout=30)
                    if retry.status_code in [200, 201]:
                        self._fetch_github_content.clear()
                        return True, retry.json()['content']['sha']
            return False, None
        except: return False, None

    def _create_empty_df(self):
        if "ledger" in self.filename:
            return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"])
        elif "funds" in self.filename:
            return pd.DataFrame(columns=["åŸºé‡‘ä»£ç ", "åŸºé‡‘åç§°", "æŒæœ‰ä»½é¢", "æˆæœ¬é‡‘é¢"])
        return pd.DataFrame()

# --- AI è§£æå™¨ (æ”¯æŒ PDF è½¬å›¾ç‰‡è§†è§‰è¯†åˆ«) ---
class BillParser:
    @staticmethod
    def chunk_text_by_lines(text, max_chars=CHUNK_SIZE):
        if len(text) <= max_chars: return [text]
        lines = text.split('\n')
        chunks, current_chunk, current_len = [], [], 0
        for line in lines:
            line_len = len(line) + 1
            if current_len + line_len > max_chars:
                if current_chunk: chunks.append("\n".join(current_chunk))
                current_chunk = [line]; current_len = line_len
            else:
                current_chunk.append(line); current_len += line_len
        if current_chunk: chunks.append("\n".join(current_chunk))
        return chunks

    @staticmethod
    def _pdf_to_images(file_bytes):
        """æ ¸å¿ƒï¼šå°†PDFäºŒè¿›åˆ¶æµè½¬æ¢ä¸ºé«˜æ¸…å›¾ç‰‡åˆ—è¡¨"""
        images = []
        try:
            with fitz.open(stream=file_bytes, filetype="pdf") as doc:
                for page in doc:
                    # matrix=fitz.Matrix(2, 2) æ”¾å¤§2å€ï¼Œæé«˜æ¸…æ™°åº¦
                    pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
                    img_bytes = pix.tobytes("png")
                    images.append(img_bytes)
        except Exception as e:
            print(f"PDFè½¬å›¾ç‰‡å¤±è´¥: {e}")
        return images

    @staticmethod
    def _call_llm_for_text(text_chunk, api_key):
        """çº¯æ–‡æœ¬å¤„ç†é€šé“ (CSV/Excel)"""
        client = get_llm_client(api_key)
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´¢åŠ¡æ•°æ®æå–åŠ©æ‰‹ã€‚
        ä»»åŠ¡ï¼šä»æ–‡æœ¬ä¸­è¯†åˆ«äº¤æ˜“è®°å½•ã€‚
        **å¼ºåˆ¶è¦æ±‚**ï¼š
        1. ä»…æå–åŒ…å«å…·ä½“æ—¥æœŸã€é‡‘é¢çš„æœ‰æ•ˆäº¤æ˜“ã€‚
        2. "category" å­—æ®µå¿…é¡»æ ¹æ®å•†æˆ·å’Œå¤‡æ³¨è¿›è¡Œ**æ™ºèƒ½æ¨æ–­**ï¼Œå¹¶**ä¸¥æ ¼**ä»ä»¥ä¸‹åˆ—è¡¨ä¸­é€‰æ‹©ä¸€é¡¹ï¼š
           {ALLOWED_CATEGORIES}
        3. æ ¼å¼å¿…é¡»ä¸ºçº¯JSONæ•°ç»„ï¼š[{{"date":"YYYY-MM-DD","type":"æ”¯å‡º/æ”¶å…¥","amount":æ•°å­—,"merchant":"å•†æˆ·åæˆ–å¤‡æ³¨","category":"ä¸Šè¿°åˆ†ç±»ä¹‹ä¸€"}}]
        
        å¾…å¤„ç†æ–‡æœ¬ï¼š
        {text_chunk}
        """
        try:
            resp = client.chat.completions.create(
                model=TEXT_MODEL_NAME, messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.0
            )
            return resp.choices[0].message.content, None
        except Exception as e: return None, str(e)

    @staticmethod
    def process_image(filename, image_bytes, api_key, mode="ledger"):
        """è§†è§‰å¤„ç†é€šé“ (å›¾ç‰‡ + PDFè½¬æ¢åçš„å›¾ç‰‡)"""
        try:
            b64_img = base64.b64encode(image_bytes).decode('utf-8')
            client = get_llm_client(api_key)
            
            if mode == "ledger":
                prompt_text = f"""
                è¯·åˆ†æè¿™å¼ è´¦å•å›¾ç‰‡ï¼ˆå¯èƒ½æ˜¯é“¶è¡Œæµæ°´æˆªå›¾æˆ–PDFé¡µé¢ï¼‰ã€‚
                
                **ä»»åŠ¡ç›®æ ‡**ï¼šæå–æ˜ç»†è¡¨æ ¼ä¸­çš„æ‰€æœ‰äº¤æ˜“ã€‚
                
                **å…³é”®è§„åˆ™**ï¼š
                1. **å¿½ç•¥å°ç« **ï¼šè¯·å¿½ç•¥è¦†ç›–åœ¨æ–‡å­—ä¸Šçš„çº¢è‰²å°ç« ï¼ˆå¦‚â€œç”µå­å›å•ä¸“ç”¨ç« â€ï¼‰ã€‚
                2. **è¯†åˆ«æ­£è´Ÿæ•°**ï¼š
                   - å¦‚æœé‡‘é¢åˆ—æ˜¾ç¤ºä¸ºè´Ÿæ•°ï¼ˆå¦‚ -10.40ï¼‰ï¼Œåˆ™ type ä¸º "æ”¯å‡º"ï¼Œamount è®°ä¸ºæ­£æ•° 10.40ã€‚
                   - å¦‚æœé‡‘é¢åˆ—æ˜¾ç¤ºä¸ºæ­£æ•°ï¼Œåˆ™ type ä¸º "æ”¶å…¥"ã€‚
                3. **å­—æ®µæ˜ å°„**ï¼š
                   - date: äº¤æ˜“æ—¥æœŸ (YYYY-MM-DD)
                   - amount: äº¤æ˜“é‡‘é¢ (çº¯æ•°å­—)
                   - merchant: ä¼˜å…ˆå–â€œå¯¹æ‰‹ä¿¡æ¯â€ã€â€œäº¤æ˜“æ‘˜è¦â€æˆ–â€œå•†æˆ·åç§°â€ã€‚
                   - category: æ ¹æ® merchant å†…å®¹ï¼Œä» {ALLOWED_CATEGORIES} ä¸­æ™ºèƒ½äºŒé€‰ä¸€ã€‚
                
                **è¾“å‡ºæ ¼å¼**ï¼š
                ä»…è¿”å›æ ‡å‡† JSON æ•°ç»„ï¼Œæ—  Markdown æ ‡è®°ï¼š
                [{{ "date": "2023-01-01", "type": "æ”¯å‡º", "amount": 10.50, "merchant": "è‚¯å¾·åŸº", "category": "é¤é¥®ç¾é£Ÿ" }}]
                """
            else:
                # åŸºé‡‘æ¨¡å¼
                prompt_text = "æå–åŸºé‡‘æŒä»“ä¿¡æ¯ã€‚è¯†åˆ«åŸºé‡‘åç§°(name)ã€åŸºé‡‘ä»£ç (code, 6ä½æ•°å­—)ã€æŒæœ‰ä»½é¢(share)ã€æŒä»“æˆæœ¬(cost, å¯é€‰)ã€‚è¿”å›JSONæ•°ç»„ï¼š[{code, name, share, cost}]"

            resp = client.chat.completions.create(
                model=VISION_MODEL_NAME,
                messages=[{
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}}
                    ]
                }],
                max_tokens=4096
            )
            data, _ = extract_json_from_text(resp.choices[0].message.content)
            
            if not data: return None, "æ— æ•°æ®", {}
            if isinstance(data, dict): data = [data]
            
            df = pd.DataFrame(data)
            
            if mode == "ledger":
                cols = {"date": "æ—¥æœŸ", "type": "ç±»å‹", "amount": "é‡‘é¢", "merchant": "å¤‡æ³¨", "category": "åˆ†ç±»"}
                df = df.rename(columns=cols)
                for c in cols.values(): 
                    if c not in df.columns: df[c] = ""
            else:
                cols = {"code": "åŸºé‡‘ä»£ç ", "name": "åŸºé‡‘åç§°", "share": "æŒæœ‰ä»½é¢", "cost": "æˆæœ¬é‡‘é¢"}
                df = df.rename(columns=cols)
                for c in cols.values():
                    if c not in df.columns: df[c] = ""
                df['åŸºé‡‘ä»£ç '] = df['åŸºé‡‘ä»£ç '].astype(str).str.replace(r'\D', '', regex=True)
            
            return df, None, {}
        except Exception as e: return None, str(e), {}

    @staticmethod
    def identify_and_parse(filename, file_bytes, api_key):
        """æ™ºèƒ½åˆ†å‘å…¥å£"""
        try:
            filename_lower = filename.lower()
            
            # --- åˆ†æ”¯ 1: PDF æ–‡ä»¶ (è½¬å›¾ç‰‡ -> è§†è§‰æ¨¡å‹) ---
            if filename_lower.endswith('.pdf'):
                images = BillParser._pdf_to_images(file_bytes)
                if not images: return None, "PDFè½¬å›¾ç‰‡å¤±è´¥", {}
                
                all_pdf_df = pd.DataFrame()
                # å¾ªç¯å¤„ç†æ¯ä¸€é¡µ PDF
                for i, img_bytes in enumerate(images):
                    res, err, _ = BillParser.process_image(f"{filename}_p{i}", img_bytes, api_key, mode="ledger")
                    if res is not None and not res.empty:
                        all_pdf_df = pd.concat([all_pdf_df, res], ignore_index=True)
                
                if all_pdf_df.empty: return None, "PDFæœªæå–åˆ°æ•°æ®", {}
                return all_pdf_df, None, {}

            # --- åˆ†æ”¯ 2: æ–‡æœ¬ç±»æ–‡ä»¶ (CSV/Excel) èµ°çº¯æ–‡æœ¬ ---
            content_text = ""
            if filename_lower.endswith('.csv'):
                try: content_text = file_bytes.decode('utf-8')
                except: content_text = file_bytes.decode('gbk', errors='ignore')
            elif filename_lower.endswith(('.xls', '.xlsx')):
                xls = pd.read_excel(BytesIO(file_bytes), sheet_name=None)
                content_text = "\n".join([f"{s}\n{d.to_csv(index=False)}" for s, d in xls.items()])
            else:
                # å…¶ä»–æ ¼å¼å°è¯•ç›´æ¥èµ°è§†è§‰ï¼ˆå¦‚ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼æ¼ç½‘ä¹‹é±¼ï¼‰
                return None, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼", {}
            
            if not content_text.strip(): return None, "ç©ºæ–‡ä»¶", {}

            chunks = BillParser.chunk_text_by_lines(content_text, CHUNK_SIZE)
            all_data = []
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                futures = {executor.submit(BillParser._call_llm_for_text, chunk, api_key): chunk for chunk in chunks}
                for future in concurrent.futures.as_completed(futures):
                    res, err = future.result()
                    if not err:
                        data, _ = extract_json_from_text(res)
                        if data: all_data.extend(data)
            
            if not all_data: return None, "æœªæå–åˆ°æ•°æ®", {}
            
            df = pd.DataFrame(all_data)
            cols = {"date": "æ—¥æœŸ", "type": "ç±»å‹", "amount": "é‡‘é¢", "merchant": "å¤‡æ³¨", "category": "åˆ†ç±»"}
            df = df.rename(columns=cols)
            for c in cols.values(): 
                if c not in df.columns: df[c] = ""
            
            df['é‡‘é¢'] = pd.to_numeric(df['é‡‘é¢'], errors='coerce').fillna(0)
            df['æ—¥æœŸ'] = df['æ—¥æœŸ'].astype(str).apply(lambda x: x.split(' ')[0])
            return df, None, {}

        except Exception as e: return None, str(e), {}

# --- ä¸»ç¨‹åº ---
def main():
    if 'debug_mode' not in st.session_state: st.session_state.debug_mode = False
    
    st.sidebar.title("âš™ï¸ è®¾ç½®")
    api_key = st.secrets.get("SILICONFLOW_API_KEY") or st.sidebar.text_input("API Key", type="password")
    gh_token = st.secrets.get("GITHUB_TOKEN")
    gh_repo = st.secrets.get("GITHUB_REPO")
    
    dm_ledger = DataManager(gh_token, gh_repo, "ledger.csv")
    dm_funds = DataManager(gh_token, gh_repo, "funds.csv")
    
    if dm_ledger.use_github:
        if st.sidebar.button("â˜ï¸ å¼ºåˆ¶åŒæ­¥äº‘ç«¯"):
            with st.spinner("åŒæ­¥ä¸­..."):
                df_l, sha_l = dm_ledger.load_data(force_refresh=True)
                st.session_state.ledger_data = df_l
                st.session_state.ledger_sha = sha_l
                df_f, sha_f = dm_funds.load_data(force_refresh=True)
                st.session_state.fund_data = df_f
                st.session_state.fund_sha = sha_f
                st.success("åŒæ­¥å®Œæˆ")
                st.rerun()
    
    if 'ledger_data' not in st.session_state:
        df, sha = dm_ledger.load_data()
        st.session_state.ledger_data = df
        st.session_state.ledger_sha = sha
        
    if 'fund_data' not in st.session_state:
        df, sha = dm_funds.load_data()
        st.session_state.fund_data = df
        st.session_state.fund_sha = sha

    st.title("ğŸ’° AI æ™ºèƒ½è´¦æœ¬ Pro (è§†è§‰å¢å¼ºç‰ˆ)")
    
    default_start, default_end = get_fiscal_range(date.today())
    col_d1, col_d2 = st.columns([2, 1])
    with col_d1:
        st.caption(f"å½“å‰ç»Ÿè®¡å‘¨æœŸ (æ¯æœˆ{BILL_CYCLE_DAY}å·åˆ‡åˆ†)")
        date_range = st.date_input("é€‰æ‹©ç»Ÿè®¡æ—¶é—´æ®µ", value=(default_start, default_end), format="YYYY-MM-DD")

    # --- è®¡ç®—èµ„äº§ ---
    df_ledger = st.session_state.ledger_data.copy()
    df_funds = st.session_state.fund_data.copy()
    
    cash_net = 0.0
    current_income = 0.0
    current_expense = 0.0
    
    if not df_ledger.empty:
        df_ledger['é‡‘é¢'] = pd.to_numeric(df_ledger['é‡‘é¢'], errors='coerce').fillna(0)
        cash_net = df_ledger[df_ledger['ç±»å‹']=='æ”¶å…¥']['é‡‘é¢'].sum() - df_ledger[df_ledger['ç±»å‹']=='æ”¯å‡º']['é‡‘é¢'].sum()
        
        if len(date_range) == 2:
            df_ledger['dt'] = pd.to_datetime(df_ledger['æ—¥æœŸ'], errors='coerce').dt.date
            start_d, end_d = date_range[0], date_range[1]
            mask_period = (df_ledger['dt'] >= start_d) & (df_ledger['dt'] <= end_d)
            df_period = df_ledger[mask_period]
            current_income = df_period[df_period['ç±»å‹']=='æ”¶å…¥']['é‡‘é¢'].sum()
            current_expense = df_period[df_period['ç±»å‹']=='æ”¯å‡º']['é‡‘é¢'].sum()
        else:
            df_period = pd.DataFrame()
    else:
        df_period = pd.DataFrame()

    fund_total_value = 0.0
    if 'fund_prices' not in st.session_state: st.session_state.fund_prices = {}
    
    if not df_funds.empty:
        df_funds['æŒæœ‰ä»½é¢'] = pd.to_numeric(df_funds['æŒæœ‰ä»½é¢'], errors='coerce').fillna(0)
        for idx, row in df_funds.iterrows():
            code = str(row['åŸºé‡‘ä»£ç '])
            share = float(row['æŒæœ‰ä»½é¢'])
            if code in st.session_state.fund_prices:
                price = st.session_state.fund_prices[code]['price']
                fund_total_value += share * price
    
    total_assets = cash_net + fund_total_value

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ğŸ’° å†å²æ€»å‡€å€¼", f"Â¥{total_assets:,.2f}")
    c2.metric("ğŸ“… æœ¬æœŸæ”¯å‡º", f"Â¥{current_expense:,.2f}")
    c3.metric("ğŸ“… æœ¬æœŸæ”¶å…¥", f"Â¥{current_income:,.2f}")
    c4.metric("ğŸ“Š åŸºé‡‘å¸‚å€¼", f"Â¥{fund_total_value:,.2f}", delta="ç‚¹å‡»ä¸‹æ–¹åˆ·æ–°" if fund_total_value==0 else "å®æ—¶")
    
    st.divider()

    t_import, t_add, t_history, t_funds, t_stats = st.tabs(["ğŸ“¥ è´¦å•å¯¼å…¥", "âœï¸ æ‰‹åŠ¨è®°è´¦", "ğŸ“‹ å†å²æ˜ç»†", "ğŸ“ˆ åŸºé‡‘æŒä»“", "ğŸ“Š æŠ¥è¡¨"])

    with t_import:
        st.info("ğŸ’¡ å‡çº§æç¤ºï¼šç°å·²æ”¯æŒ PDF é“¶è¡Œè´¦å•çš„è§†è§‰è¯†åˆ«ï¼è‡ªåŠ¨å¿½ç•¥çº¢ç« ã€è‡ªåŠ¨å¤„ç†è´Ÿæ•°æ”¯å‡ºã€‚")
        files = st.file_uploader("ä¸Šä¼ è´¦å• (PDF/å›¾ç‰‡/CSV/Excel)", accept_multiple_files=True)
        if files and st.button("ğŸš€ å¼€å§‹è¯†åˆ«è´¦å•", type="primary"):
            if not api_key: st.error("è¯·é…ç½® API Key"); st.stop()
            
            new_df = pd.DataFrame()
            tasks = []
            
            # é¢„å¤„ç†ï¼šåŒºåˆ†å›¾ç‰‡/PDF (èµ°è§†è§‰) å’Œ CSV/Excel (èµ°æ–‡æœ¬)
            # æ³¨æ„ï¼šBillParser.identify_and_parse å†…éƒ¨å·²ç»å¤„ç†äº† PDF->å›¾ç‰‡ çš„é€»è¾‘
            # æˆ‘ä»¬åªéœ€è¦æ ¹æ®æ–‡ä»¶åç¼€ä¼ å‚å³å¯
            
            # è¿™é‡Œä¸ºäº†ç®€åŒ–è¿›åº¦æ¡ï¼Œæˆ‘ä»¬è¿˜æ˜¯æŠŠæ¯ä¸ªæ–‡ä»¶ä½œä¸ºä¸€ä¸ªä»»åŠ¡
            with st.status("æ­£åœ¨AIè¯†åˆ«...") as status:
                with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                    futures = {}
                    for f in files:
                        f.seek(0)
                        file_bytes = f.read()
                        
                        # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œç›´æ¥è°ƒ visual å¤„ç† (ä¸ºäº†å¤ç”¨é€»è¾‘ï¼Œidentify_and_parse ä¹Ÿå¯ä»¥å¤„ç†ï¼Œä½†è¿™é‡Œæˆ‘ä»¬æ˜¾å¼åŒºåˆ†ä¸€ä¸‹æ›´æ¸…æ™°)
                        ext = f.name.split('.')[-1].lower()
                        if ext in ['png', 'jpg', 'jpeg']:
                             futures[executor.submit(BillParser.process_image, f.name, file_bytes, api_key, "ledger")] = f.name
                        else:
                             # PDF, Excel, CSV éƒ½äº¤ç»™ identify_and_parse æ™ºèƒ½åˆ¤æ–­
                             futures[executor.submit(BillParser.identify_and_parse, f.name, file_bytes, api_key)] = f.name
                    
                    for future in concurrent.futures.as_completed(futures):
                        try:
                            res, err, _ = future.result()
                            if res is not None: new_df = pd.concat([new_df, res], ignore_index=True)
                        except Exception as e: st.write(f"Error: {e}")
                status.update(label="å®Œæˆ", state="complete")

            if not new_df.empty:
                merged, added = DataManager.merge_data(st.session_state.ledger_data, new_df)
                if added > 0:
                    ok, sha = dm_ledger.save_data(merged, st.session_state.get('ledger_sha'))
                    if ok:
                        st.session_state.ledger_data = merged
                        st.session_state.ledger_sha = sha
                        st.success(f"æˆåŠŸå¯¼å…¥ {added} æ¡è®°å½•")
                    else: st.error("ä¿å­˜å¤±è´¥")
                else: st.warning("æœªå‘ç°æ–°æ•°æ® (å¯èƒ½å·²å­˜åœ¨)")

    with t_add:
        with st.form("manual"):
            c1, c2, c3 = st.columns(3)
            d = c1.date_input("æ—¥æœŸ", date.today())
            t = c2.selectbox("ç±»å‹", ["æ”¯å‡º", "æ”¶å…¥"])
            a = c3.number_input("é‡‘é¢", min_value=0.01)
            c4, c5 = st.columns([1,2])
            cat = c4.selectbox("åˆ†ç±»", ALLOWED_CATEGORIES)
            rem = c5.text_input("å¤‡æ³¨")
            if st.form_submit_button("ä¿å­˜", width="stretch"):
                row = pd.DataFrame([{"æ—¥æœŸ":str(d),"ç±»å‹":t,"é‡‘é¢":a,"åˆ†ç±»":cat,"å¤‡æ³¨":rem}])
                merged, added = DataManager.merge_data(st.session_state.ledger_data, row)
                ok, sha = dm_ledger.save_data(merged, st.session_state.get('ledger_sha'))
                if ok: 
                    st.session_state.ledger_data = merged
                    st.session_state.ledger_sha = sha
                    st.success("ä¿å­˜æˆåŠŸ")

    with t_history:
        if st.session_state.ledger_data.empty: st.info("æ— æ•°æ®")
        else:
            df_show = st.session_state.ledger_data.sort_values('æ—¥æœŸ', ascending=False)
            edited_df = st.data_editor(
                df_show, 
                use_container_width=True, 
                num_rows="dynamic",
                key="editor_history",
                column_config={
                    "æ—¥æœŸ": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
                    "åˆ†ç±»": st.column_config.SelectboxColumn(options=ALLOWED_CATEGORIES),
                    "é‡‘é¢": st.column_config.NumberColumn(format="%.2f")
                }
            )
            if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹"):
                ok, sha = dm_ledger.save_data(edited_df, st.session_state.get('ledger_sha'))
                if ok:
                    st.session_state.ledger_data = edited_df
                    st.session_state.ledger_sha = sha
                    st.success("å·²æ›´æ–°")
                    time.sleep(1)
                    st.rerun()

    with t_funds:
        c_f1, c_f2 = st.columns([1, 3])
        with c_f1:
            st.subheader("ğŸ“¸ å¯¼å…¥æŒä»“")
            fund_files = st.file_uploader("ä¸Šä¼ æŒä»“æˆªå›¾", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
            if fund_files and st.button("è¯†åˆ«æŒä»“"):
                new_funds = pd.DataFrame()
                with st.status("è¯†åˆ«ä¸­...") as status:
                    for f in fund_files:
                        f.seek(0)
                        res, err, _ = BillParser.process_image(f.name, f.read(), api_key, mode="fund")
                        if res is not None: new_funds = pd.concat([new_funds, res], ignore_index=True)
                    status.update(label="å®Œæˆ", state="complete")
                
                if not new_funds.empty:
                    current_funds = st.session_state.fund_data
                    merged_funds = pd.concat([current_funds, new_funds], ignore_index=True)
                    merged_funds = DataManager._clean_fund_types(merged_funds)
                    ok, sha = dm_funds.save_data(merged_funds, st.session_state.get('fund_sha'))
                    if ok:
                        st.session_state.fund_data = merged_funds
                        st.session_state.fund_sha = sha
                        st.success("æŒä»“æ›´æ–°")
                        st.rerun()
        
        with c_f2:
            st.subheader("ğŸ“ˆ æŒä»“åˆ—è¡¨")
            col_act1, col_act2 = st.columns([1, 5])
            if col_act1.button("ğŸ”„ åˆ·æ–°è¡Œæƒ…"):
                codes = st.session_state.fund_data['åŸºé‡‘ä»£ç '].unique()
                progress = st.progress(0)
                for i, code in enumerate(codes):
                    if not code: continue
                    val, name, t_str = get_fund_realtime_valuation(code)
                    if val > 0:
                        st.session_state.fund_prices[code] = {"price": val, "name": name, "time": t_str}
                    progress.progress((i + 1) / len(codes))
                st.rerun()
            
            if st.session_state.fund_data.empty:
                st.info("æš‚æ— æŒä»“")
            else:
                display_data = []
                for _, row in st.session_state.fund_data.iterrows():
                    code = str(row['åŸºé‡‘ä»£ç '])
                    share = float(row['æŒæœ‰ä»½é¢'])
                    cost = float(row['æˆæœ¬é‡‘é¢'])
                    
                    curr_info = st.session_state.fund_prices.get(code, {})
                    curr_price = curr_info.get('price', 0)
                    curr_name = curr_info.get('name', row['åŸºé‡‘åç§°'])
                    
                    mkt_value = share * curr_price if curr_price > 0 else 0
                    profit = mkt_value - cost if (mkt_value > 0 and cost > 0) else 0
                    
                    display_data.append({
                        "åŸºé‡‘ä»£ç ": code,
                        "åŸºé‡‘åç§°": curr_name,
                        "æŒæœ‰ä»½é¢": share,
                        "æœ€æ–°å‡€å€¼": curr_price,
                        "æŒä»“å¸‚å€¼": mkt_value,
                        "å‚è€ƒç›ˆäº": profit
                    })
                
                df_disp = pd.DataFrame(display_data)
                edited_funds = st.data_editor(
                    df_disp,
                    use_container_width=True,
                    key="editor_funds",
                    column_config={
                        "æŒæœ‰ä»½é¢": st.column_config.NumberColumn(format="%.2f"),
                        "æœ€æ–°å‡€å€¼": st.column_config.NumberColumn(format="%.4f"),
                        "æŒä»“å¸‚å€¼": st.column_config.NumberColumn(format="%.2f"),
                        "å‚è€ƒç›ˆäº": st.column_config.NumberColumn(format="%.2f"),
                    },
                    disabled=["æœ€æ–°å‡€å€¼", "æŒä»“å¸‚å€¼", "å‚è€ƒç›ˆäº"]
                )
                if st.button("ğŸ’¾ ä¿å­˜æŒä»“ä¿®æ”¹"):
                    save_funds = edited_funds[['åŸºé‡‘ä»£ç ', 'åŸºé‡‘åç§°', 'æŒæœ‰ä»½é¢']].copy()
                    save_funds['æˆæœ¬é‡‘é¢'] = 0 
                    ok, sha = dm_funds.save_data(save_funds, st.session_state.get('fund_sha'))
                    if ok:
                        st.session_state.fund_data = save_funds
                        st.session_state.fund_sha = sha
                        st.success("å·²æ›´æ–°")

    with t_stats:
        if df_period.empty:
            st.info("æœ¬æœŸæ— æ•°æ®")
        else:
            df_exp = df_period[df_period['ç±»å‹'] == 'æ”¯å‡º']
            col_chart1, col_chart2 = st.columns(2)
            with col_chart1:
                st.subheader("æ”¯å‡ºç»“æ„")
                if not df_exp.empty:
                    fig_pie = px.pie(df_exp, values='é‡‘é¢', names='åˆ†ç±»', hole=0.4)
                    st.plotly_chart(fig_pie, use_container_width=True)
            
            with col_chart2:
                st.subheader("èµ„äº§è¶‹åŠ¿")
                df_sorted = df_ledger.sort_values('æ—¥æœŸ')
                df_sorted['net'] = df_sorted.apply(lambda x: x['é‡‘é¢'] if x['ç±»å‹']=='æ”¶å…¥' else -x['é‡‘é¢'], axis=1)
                df_sorted['asset'] = df_sorted['net'].cumsum()
                fig_line = px.line(df_sorted, x='æ—¥æœŸ', y='asset')
                st.plotly_chart(fig_line, use_container_width=True)

if __name__ == "__main__":
    main()
