import streamlit as st
import pandas as pd
import datetime
from datetime import date
import requests
import json
import base64
from io import StringIO, BytesIO
import os

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI æ™ºèƒ½è´¦æœ¬", page_icon="ğŸ’°", layout="wide")

# --- å¸¸é‡é…ç½® ---
DEFAULT_TARGET_SPEND = 60.0  # æ¯æ—¥ä½“é¢æ”¯å‡ºæ ‡å‡†
GITHUB_API_URL = "https://api.github.com"
# æ¨èçš„è§†è§‰æ¨¡å‹ï¼ŒSiliconFlow ä¸Šå¯ç”¨
VISION_MODEL_NAME = "Qwen/Qwen3-VL-8B-Instruct" 
# æ–‡æœ¬åˆ†ææ¨¡å‹
TEXT_MODEL_NAME = "deepseek-ai/DeepSeek-V3.2"

# --- å­˜å‚¨ç±»ï¼šå¤„ç†æ•°æ®ä¿å­˜ ---
class DataManager:
    """æ•°æ®ç®¡ç†ç±»ï¼Œæ”¯æŒ GitHub è¿œç¨‹å­˜å‚¨å’Œæœ¬åœ° CSV å­˜å‚¨"""
    def __init__(self, github_token=None, repo=None, filename="ledger.csv"):
        self.github_token = github_token
        # è‡ªåŠ¨å¤„ç†å®Œæ•´çš„ GitHub URLï¼Œæå– owner/repo
        if repo and repo.startswith("http"):
            self.repo = repo.rstrip("/").split("github.com/")[-1]
        else:
            self.repo = repo
        self.filename = filename
        self.use_github = bool(github_token and self.repo)

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        if self.use_github:
            return self._load_from_github()
        else:
            return self._load_from_local()

    def save_data(self, df, sha=None):
        """ä¿å­˜æ•°æ®"""
        if self.use_github:
            return self._save_to_github(df, sha)
        else:
            return self._save_to_local(df)

    # --- æœ¬åœ°å­˜å‚¨é€»è¾‘ ---
    def _load_from_local(self):
        if os.path.exists(self.filename):
            return pd.read_csv(self.filename), None
        return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None

    def _save_to_local(self, df):
        df.to_csv(self.filename, index=False)
        return True

    # --- GitHub å­˜å‚¨é€»è¾‘ ---
    def _load_from_github(self):
        headers = {
            "Authorization": f"token {self.github_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        url = f"{GITHUB_API_URL}/repos/{self.repo}/contents/{self.filename}"
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            content = response.json()
            csv_str = base64.b64decode(content['content']).decode('utf-8')
            try:
                return pd.read_csv(StringIO(csv_str)), content['sha']
            except pd.errors.EmptyDataError:
                return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), content['sha']
        elif response.status_code == 404:
            return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None
        else:
            st.error(f"GitHub è¯»å–é”™è¯¯: {response.status_code}")
            return pd.DataFrame(columns=["æ—¥æœŸ", "ç±»å‹", "é‡‘é¢", "å¤‡æ³¨", "åˆ†ç±»"]), None

    def _save_to_github(self, df, sha):
        headers = {
            "Authorization": f"token {self.github_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        csv_str = df.to_csv(index=False)
        content_bytes = base64.b64encode(csv_str.encode('utf-8')).decode('utf-8')
        
        url = f"{GITHUB_API_URL}/repos/{self.repo}/contents/{self.filename}"
        data = {
            "message": f"Update ledger {datetime.datetime.now()}",
            "content": content_bytes
        }
        if sha:
            data["sha"] = sha
            
        response = requests.put(url, headers=headers, data=json.dumps(data))
        return response.status_code in [200, 201]

# --- è´¦å•è§£æç±» ---
class BillParser:
    @staticmethod
    def parse_wechat(file):
        """è§£æå¾®ä¿¡è´¦å• CSV"""
        try:
            content = file.getvalue().decode('utf-8')
        except UnicodeDecodeError:
            file.seek(0)
            content = file.getvalue().decode('gbk', errors='ignore')

        lines = content.split('\n')
        start_row = 0
        for i, line in enumerate(lines):
            if "äº¤æ˜“æ—¶é—´" in line:
                start_row = i
                break
        
        if start_row == 0 and "äº¤æ˜“æ—¶é—´" not in lines[0]:
             return None, "æœªæ‰¾åˆ°å¾®ä¿¡è´¦å•è¡¨å¤´ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼"

        try:
            df = pd.read_csv(StringIO(content), header=start_row)
        except Exception as e:
            return None, f"CSVè§£æå¤±è´¥: {str(e)}"

        # å¾®ä¿¡å­—æ®µæ¸…æ´—
        df.columns = [c.strip() for c in df.columns]
        required_cols = ['äº¤æ˜“æ—¶é—´', 'é‡‘é¢(å…ƒ)', 'æ”¶/æ”¯', 'äº¤æ˜“å¯¹æ–¹', 'å•†å“', 'å½“å‰çŠ¶æ€']
        
        if not all(col in df.columns for col in required_cols):
             return None, f"åˆ—åä¸åŒ¹é…ï¼Œæ£€æµ‹åˆ°çš„åˆ—: {list(df.columns)}"

        df = df[df['å½“å‰çŠ¶æ€'] == 'æ”¯ä»˜æˆåŠŸ']
        
        results = []
        for _, row in df.iterrows():
            amt = float(str(row['é‡‘é¢(å…ƒ)']).replace('Â¥', '').replace(',', ''))
            row_type = row['æ”¶/æ”¯']
            
            final_type = "æ”¯å‡º" if row_type == "æ”¯å‡º" else "æ”¶å…¥"
            if row_type == "/" or row_type == "ä¸è®¡æ”¶æ”¯":
                continue

            try:
                d_str = pd.to_datetime(row['äº¤æ˜“æ—¶é—´']).strftime('%Y-%m-%d')
            except:
                continue

            results.append({
                "æ—¥æœŸ": d_str,
                "ç±»å‹": final_type,
                "é‡‘é¢": amt,
                "å¤‡æ³¨": f"{row['äº¤æ˜“å¯¹æ–¹']} - {row['å•†å“']}",
                "åˆ†ç±»": "å¯¼å…¥/æœªåˆ†ç±»"
            })
            
        return pd.DataFrame(results), None

    @staticmethod
    def parse_alipay(file):
        """è§£ææ”¯ä»˜å®è´¦å•"""
        try:
            content = file.getvalue().decode('gbk')
        except UnicodeDecodeError:
            file.seek(0)
            content = file.getvalue().decode('utf-8', errors='ignore')

        lines = content.split('\n')
        start_row = 0
        for i, line in enumerate(lines):
            if "äº¤æ˜“æ—¶é—´" in line and "äº¤æ˜“å¯¹æ–¹" in line:
                start_row = i
                break
        
        try:
            df = pd.read_csv(StringIO(content), header=start_row, encoding='gbk')
        except:
             df = pd.read_csv(StringIO(content), header=start_row)

        df.columns = [c.strip() for c in df.columns]
        
        if 'äº¤æ˜“çŠ¶æ€' in df.columns:
            df = df[df['äº¤æ˜“çŠ¶æ€'].isin(['äº¤æ˜“æˆåŠŸ', 'æ”¯ä»˜æˆåŠŸ', 'å·²æ”¯å‡º'])]

        results = []
        for _, row in df.iterrows():
            if 'é‡‘é¢' not in row or pd.isna(row['é‡‘é¢']): continue

            amt = float(str(row['é‡‘é¢']))
            row_type = str(row.get('æ”¶/æ”¯', '')).strip()
            
            final_type = "æ”¯å‡º" if row_type == "æ”¯å‡º" else "æ”¶å…¥"
            if row_type == "ä¸è®¡æ”¶æ”¯" or row_type == "":
                continue

            try:
                d_str = pd.to_datetime(row['äº¤æ˜“æ—¶é—´']).strftime('%Y-%m-%d')
            except:
                continue
            
            cat = row.get('äº¤æ˜“åˆ†ç±»', 'å¯¼å…¥/æœªåˆ†ç±»')
            merchant = row.get('äº¤æ˜“å¯¹æ–¹', '')
            desc = row.get('å•†å“è¯´æ˜', '')

            results.append({
                "æ—¥æœŸ": d_str,
                "ç±»å‹": final_type,
                "é‡‘é¢": amt,
                "å¤‡æ³¨": f"{merchant} {desc}".strip(),
                "åˆ†ç±»": cat
            })
            
        return pd.DataFrame(results), None

# --- AI å¤„ç†å‡½æ•° ---
def process_bill_image(image_file, api_key):
    if not api_key:
        return None, "æœªé…ç½® API Key"

    image_bytes = image_file.getvalue()
    base64_image = base64.b64encode(image_bytes).decode('utf-8')

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    prompt = """
    è¯·è¯†åˆ«è¿™å¼ è´¦å•å›¾ç‰‡ã€‚æå–ä»¥ä¸‹å­—æ®µå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š
    1. date (æ ¼å¼YYYY-MM-DD)
    2. amount (æ•°å­—ç±»å‹ï¼Œä¸è¦å¸¦è´§å¸ç¬¦å·)
    3. merchant (å•†æˆ·åæˆ–äº¤æ˜“è¯´æ˜)
    4. category (ä»ä»¥ä¸‹é€‰æ‹©æœ€æ¥è¿‘çš„: é¤é¥®, äº¤é€š, è´­ç‰©, å±…ä½, å¨±ä¹, å·¥èµ„, å…¶ä»–)
    5. type (æ”¯å‡º æˆ– æ”¶å…¥)
    
    ç›´æ¥è¿”å›JSONï¼Œä¸éœ€è¦ ```json æ ‡è®°ã€‚
    """

    payload = {
        "model": VISION_MODEL_NAME, 
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        "max_tokens": 512
    }

    try:
        # ä¿®æ­£ URL æ ¼å¼é—®é¢˜
        response = requests.post(
            "[https://api.siliconflow.cn/v1/chat/completions](https://api.siliconflow.cn/v1/chat/completions)",
            headers=headers,
            json=payload,
            timeout=45
        )
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            clean_content = content.replace("```json", "").replace("```", "").strip()
            return json.loads(clean_content), None
        else:
            return None, f"API Error {response.status_code}: {response.text}"
    except Exception as e:
        return None, f"è¯·æ±‚å¼‚å¸¸: {str(e)}"

# --- ä¸»ç¨‹åº ---
def main():
    # 1. é…ç½®åŠ è½½
    st.sidebar.title("âš™ï¸ ä¸ªäººè´¢åŠ¡è®¾ç½®")
    
    sf_api_key = st.secrets.get("SILICONFLOW_API_KEY", "")
    github_token = st.secrets.get("GITHUB_TOKEN", "")
    github_repo = st.secrets.get("GITHUB_REPO", "")

    dm = DataManager(github_token, github_repo)
    
    if dm.use_github:
        st.sidebar.success(f"â˜ï¸ æ•°æ®å­˜å‚¨: GitHub ({github_repo})")
    else:
        st.sidebar.warning("ğŸ“‚ æ•°æ®å­˜å‚¨: æœ¬åœ°æ¨¡å¼ (é‡å¯åStreamlit Cloudä¼šé‡ç½®æ•°æ®)")

    payday = st.sidebar.number_input("æ¯æœˆå‘è–ªæ—¥", 1, 31, 10)
    current_cash = st.sidebar.number_input("å½“å‰ç°é‡‘/ä½™é¢", value=3000.0)

    # 2. åŠ è½½æ•°æ®
    if 'ledger_data' not in st.session_state:
        df, sha = dm.load_data()
        st.session_state.ledger_data = df
        st.session_state.github_sha = sha

    # 3. è´¢åŠ¡æ¦‚è§ˆ
    st.title("ğŸ’° æç®€è´¦æœ¬")
    
    today = date.today()
    if today.day >= payday:
        next_pay_date = date(today.year + (1 if today.month == 12 else 0), 1 if today.month == 12 else today.month + 1, payday)
    else:
        next_pay_date = date(today.year, today.month, payday)
    
    days_left = (next_pay_date - today).days
    
    col1, col2, col3 = st.columns(3)
    col1.metric("å½“å‰ä½™é¢", f"Â¥{current_cash:,.2f}")
    col2.metric("è·ç¦»å‘å·¥èµ„", f"{days_left} å¤©")
    
    if days_left > 0:
        daily_budget = current_cash / days_left
        gap = daily_budget - DEFAULT_TARGET_SPEND
        col3.metric("æ¯æ—¥å¯ç”¨", f"Â¥{daily_budget:.1f}", 
                    f"{gap:+.1f} (vs Â¥{DEFAULT_TARGET_SPEND})",
                    delta_color="normal" if gap >= 0 else "inverse")
    else:
        col3.metric("æ¯æ—¥å¯ç”¨", "N/A", "ä»Šæ—¥å‘è–ªï¼")

    st.divider()

    # 4. è®°è´¦åŠŸèƒ½åŒº
    tab_ocr, tab_manual, tab_import = st.tabs(["ğŸ“¸ æˆªå›¾è®°è´¦ (OCR)", "âœï¸ æ‰‹åŠ¨è®°è´¦", "ğŸ“‚ å¯¼å…¥è´¦å•(Excel/CSV)"])

    # --- Tab 1: OCR ---
    with tab_ocr:
        c1, c2 = st.columns([1, 1])
        with c1:
            # ä¿®å¤: æ˜ç¡®è®¾ç½® label ä¸º "ä¸Šä¼ æˆªå›¾"ï¼Œé˜²æ­¢å‡ºç° label ä¸èƒ½ä¸ºç©ºçš„è­¦å‘Š
            uploaded_file = st.file_uploader("ä¸Šä¼ æˆªå›¾", type=['png', 'jpg', 'jpeg'], key="ocr_upload")
            if uploaded_file and st.button("å¼€å§‹è¯†åˆ«", key="btn_ocr"):
                if not sf_api_key:
                    st.error("è¯·å…ˆé…ç½® SILICONFLOW_API_KEY")
                else:
                    with st.spinner("AI æ­£åœ¨æå–ä¿¡æ¯..."):
                        data, err = process_bill_image(uploaded_file, sf_api_key)
                        if err:
                            st.error(err)
                        else:
                            st.success("è¯†åˆ«æˆåŠŸï¼")
                            st.session_state.temp_ocr_data = data
        
        with c2:
            if 'temp_ocr_data' in st.session_state:
                res = st.session_state.temp_ocr_data
                with st.form("ocr_confirm"):
                    st.write("ç¡®è®¤è¯†åˆ«ç»“æœï¼š")
                    o_date = st.date_input("æ—¥æœŸ", pd.to_datetime(res.get('date', str(date.today()))))
                    o_type = st.selectbox("ç±»å‹", ["æ”¯å‡º", "æ”¶å…¥"], index=1 if res.get('type') == 'æ”¶å…¥' else 0)
                    o_amt = st.number_input("é‡‘é¢", float(res.get('amount', 0)))
                    o_cat = st.text_input("åˆ†ç±»", res.get('category', 'é¤é¥®'))
                    o_desc = st.text_input("å¤‡æ³¨", res.get('merchant', ''))
                    
                    if st.form_submit_button("âœ… ç¡®è®¤æ·»åŠ "):
                        new_row = {"æ—¥æœŸ": str(o_date), "ç±»å‹": o_type, "é‡‘é¢": o_amt, "å¤‡æ³¨": o_desc, "åˆ†ç±»": o_cat}
                        st.session_state.ledger_data = pd.concat([st.session_state.ledger_data, pd.DataFrame([new_row])], ignore_index=True)
                        dm.save_data(st.session_state.ledger_data, st.session_state.get('github_sha'))
                        st.session_state.github_sha = dm.load_data()[1]
                        del st.session_state.temp_ocr_data
                        st.rerun()

    # --- Tab 2: Manual ---
    with tab_manual:
        with st.form("manual_form"):
            c_m1, c_m2 = st.columns(2)
            m_date = c_m1.date_input("æ—¥æœŸ", date.today())
            m_type = c_m2.selectbox("ç±»å‹", ["æ”¯å‡º", "æ”¶å…¥"])
            m_amt = c_m1.number_input("é‡‘é¢", step=1.0)
            m_cat = c_m2.selectbox("åˆ†ç±»", ["é¤é¥®", "äº¤é€š", "è´­ç‰©", "å±…ä½", "å¨±ä¹", "å·¥èµ„", "å…¶ä»–"])
            m_desc = st.text_input("å¤‡æ³¨")
            
            if st.form_submit_button("ğŸ’¾ ä¿å­˜è®°å½•"):
                new_row = {"æ—¥æœŸ": str(m_date), "ç±»å‹": m_type, "é‡‘é¢": m_amt, "å¤‡æ³¨": m_desc, "åˆ†ç±»": m_cat}
                st.session_state.ledger_data = pd.concat([st.session_state.ledger_data, pd.DataFrame([new_row])], ignore_index=True)
                dm.save_data(st.session_state.ledger_data, st.session_state.get('github_sha'))
                st.session_state.github_sha = dm.load_data()[1]
                st.rerun()

    # --- Tab 3: Import ---
    with tab_import:
        st.info("ğŸ’¡ æç¤ºï¼šæ”¯æŒå¾®ä¿¡æˆ–æ”¯ä»˜å®å¯¼å‡ºçš„ CSV æ–‡ä»¶ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨å¿½ç•¥å·²å­˜åœ¨çš„è®°å½•ï¼ˆæ—¥æœŸã€é‡‘é¢ã€ç±»å‹ã€å¤‡æ³¨å®Œå…¨ä¸€è‡´çš„ï¼‰ã€‚")
        import_file = st.file_uploader("ä¸Šä¼ è´¦å•æ–‡ä»¶", type=['csv'], key="bill_import")
        
        if import_file:
            bill_type = st.radio("é€‰æ‹©è´¦å•æ¥æº", ["å¾®ä¿¡", "æ”¯ä»˜å®"], horizontal=True)
            if st.button("å¼€å§‹è§£æå¹¶å¯¼å…¥"):
                with st.spinner("æ­£åœ¨è§£ææ–‡ä»¶..."):
                    if bill_type == "å¾®ä¿¡":
                        df_new, err = BillParser.parse_wechat(import_file)
                    else:
                        df_new, err = BillParser.parse_alipay(import_file)
                    
                    if err:
                        st.error(err)
                    elif df_new is not None and not df_new.empty:
                        # 1. ç»„åˆæ–°æ—§æ•°æ®
                        old_df = st.session_state.ledger_data.copy()
                        
                        # 2. å»é‡é€»è¾‘
                        combined = pd.concat([old_df, df_new], ignore_index=True)
                        deduplicated = combined.drop_duplicates(subset=['æ—¥æœŸ', 'é‡‘é¢', 'å¤‡æ³¨', 'ç±»å‹'], keep='first')
                        
                        # 3. è®¡ç®—æ–°å¢æ•°é‡
                        added_count = len(deduplicated) - len(old_df)
                        ignored_count = len(df_new) - added_count
                        
                        if added_count > 0:
                            if dm.save_data(deduplicated, st.session_state.get('github_sha')):
                                st.session_state.ledger_data = deduplicated
                                st.session_state.github_sha = dm.load_data()[1]
                                st.success(f"ğŸ‰ æˆåŠŸå¯¼å…¥ {added_count} æ¡æ–°è®°å½•ï¼")
                                if ignored_count > 0:
                                    st.warning(f"ğŸ›¡ï¸ è‡ªåŠ¨å¿½ç•¥äº† {ignored_count} æ¡å·²å­˜åœ¨çš„é‡å¤è®°å½•ã€‚")
                                st.rerun()
                            else:
                                st.error("ä¿å­˜å¤±è´¥")
                        else:
                            st.warning(f"æ‰€æœ‰ {len(df_new)} æ¡è®°å½•å‡å·²å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°ã€‚")
                    else:
                        st.warning("è§£ææˆåŠŸï¼Œä½†æ²¡æœ‰å‘ç°æœ‰æ•ˆäº¤æ˜“è®°å½•ã€‚")

    st.divider()

    # 5. å†å²è´¦å• & å¯è§†åŒ–
    if not st.session_state.ledger_data.empty:
        st.subheader("ğŸ“Š å†å²è´¦å•")
        
        edited_df = st.data_editor(
            st.session_state.ledger_data,
            num_rows="dynamic",
            use_container_width=True,
            key="history_editor"
        )

        col_save, col_info = st.columns([1, 4])
        with col_save:
            if st.button("ğŸ”„ åŒæ­¥è¡¨æ ¼ä¿®æ”¹"):
                if dm.save_data(edited_df, st.session_state.get('github_sha')):
                    st.session_state.ledger_data = edited_df
                    st.session_state.github_sha = dm.load_data()[1]
                    st.success("åŒæ­¥æˆåŠŸ")
                    st.rerun()
        
        st.divider()
        st.subheader("ğŸ“ˆ æ¶ˆè´¹é€è§†")
        
        chart_df = st.session_state.ledger_data.copy()
        chart_df['é‡‘é¢'] = pd.to_numeric(chart_df['é‡‘é¢'], errors='coerce').fillna(0)
        chart_df['æ—¥æœŸ'] = pd.to_datetime(chart_df['æ—¥æœŸ']).dt.date
        expense_df = chart_df[chart_df['ç±»å‹'] == 'æ”¯å‡º']
        
        if not expense_df.empty:
            t1, t2 = st.tabs(["ğŸ“Š åˆ†ç±»å æ¯”", "ğŸ“‰ æ¯æ—¥è¶‹åŠ¿"])
            with t1:
                st.bar_chart(expense_df.groupby('åˆ†ç±»')['é‡‘é¢'].sum().sort_values(ascending=False), color="#FF4B4B")
            with t2:
                st.line_chart(expense_df.groupby('æ—¥æœŸ')['é‡‘é¢'].sum())
    else:
        st.info("æš‚æ— æ•°æ®")

    # 6. AI åˆ†æ
    with st.expander("ğŸ¤– AI è´¢åŠ¡åˆ†æ"):
        if st.button("åˆ†ææˆ‘çš„å¼€é”€"):
            if sf_api_key and not st.session_state.ledger_data.empty:
                with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                    summary = st.session_state.ledger_data.to_string()
                    payload = {
                        "model": TEXT_MODEL_NAME, 
                        "messages": [{"role": "user", "content": f"åˆ†æè¿™ä»½è´¦å•ï¼ŒæŒ‡å‡ºé—®é¢˜ï¼š\n{summary}"}]
                    }
                    try:
                        # ä¿®å¤ URL æ ¼å¼é—®é¢˜
                        r = requests.post("[https://api.siliconflow.cn/v1/chat/completions](https://api.siliconflow.cn/v1/chat/completions)", 
                                        headers={"Authorization": f"Bearer {sf_api_key}"}, json=payload)
                        st.markdown(r.json()['choices'][0]['message']['content'])
                    except Exception as e:
                        st.error(f"AI æœåŠ¡å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()
